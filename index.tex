% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Open Access Article Data Analysis Workflow},
  pdfauthor={APC Working Group (Leigh-Ann Butler, Lauren Byl, Erin Calhoun, Erin Fields, Jason Friedman, Madelaine Hare, Jaclyn McLean, Stephanie Savage, Mark Swartz)},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Open Access Article Data Analysis Workflow}
\author{APC Working Group (Leigh-Ann Butler, Lauren Byl, Erin Calhoun,
Erin Fields, Jason Friedman, Madelaine Hare, Jaclyn McLean, Stephanie
Savage, Mark Swartz)}
\date{2025-07-17}

\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter*{Preface}\label{preface}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

This is a Quarto book.

To learn more about Quarto books visit
\url{https://quarto.org/docs/books}.

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{+} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2
\end{verbatim}

\bookmarksetup{startatroot}

\chapter{Initial considerations}\label{initial-considerations}

\section{\texorpdfstring{\textbf{Purpose}}{Purpose}}\label{purpose}

It's hard to know exactly what a dataset can tell you until you've seen
what's in it. But starting with a few key questions can help you focus
and choose the right data to analyze. With so many data points
available, it can get overwhelming without a clear idea of what you're
looking for. The list below shows some areas you can explore using the
tools mentioned in this document.~

\begin{itemize}
\item
  The yearly amount of money spent on APCs.~
\item
  The yearly amount saved through discounts and memberships.~
\item
  Type of OA model most prevalent, including the type of open licensed
  assigned to articles
\item
  The number of articles added/not added to your institutional
  repository.~
\item
  When the article was added to an OA repository using the oa-date and
  repository information from Unpaywall. This could yield interesting
  details on faculty processes for making content OA
  (e.g.~pre-publication, post-publication, etc.)
\item
  Analyze the subject areas and faculties/departments where open access
  publishing is occurring/not occurring. This could assist with advocacy
  and outreach opportunities to promote OA.
\item
  The largest OA outputs by publisher. This could lead to negotiations
  around further discounts or moving toward transformative agreements.
\item
  Using the corresponding author data, gather emails for a research
  project on faculty OA practices.
\item
  Track and compare the impact of OA agreements over time. For example,
  if the Public Library of Science (PLOS) agreement started in 2023,
  tracking publications and comparing them with past years will show
  whether there is an increase in PLOS publications after the
  transformative agreement.
\item
  Evaluate agreements for the OA Collection team to identify how much
  your institution publishes with the publisher. This will help guide
  what we consider for purchasing when we get requests.
\item
  Identify SSHRC/NSERC/CIHR-funded research meeting the OA requirements
\end{itemize}

\section{\texorpdfstring{\textbf{Resources}}{Resources}}\label{resources}

Resourcing for data refining and analysis needs to be considered to
ensure you are scoping your project appropriately.~ The resources of
time, people, training, and tools will impact what you can accomplish
and will affect the ``questions'' you can answer with your dataset.~

The workflows described here are meant to guide how to gather and
analyze data based on the resources available to you at your
institution. With this in mind, we offer both a scaled-down and
scaled-up workflow in the second part of this document.~~

The following sections outline key considerations on resourcing your
data project.

\subsubsection{\texorpdfstring{\textbf{People \&
Time}}{People \& Time}}\label{people-time}

With more time, the more detailed and comprehensive the dataset will
be.~

Time for data pulling if using multiple datasets and merging.~

Time for data cleaning and refinement.~

Exactness of the data takes time (gathering exact APC costs over
estimates).~

More staff/librarian support, the more work can be done on the data.

\subsubsection{\texorpdfstring{\textbf{Training}}{Training}}\label{training}

Knowledge needed to complete the analysis - excel/open refine/R maybe

\subsubsection{\texorpdfstring{\textbf{Tools}}{Tools}}\label{tools}

Choosing the right tool is the first step in collecting and analyzing
data. No single tool covers everything, and each has its limits and
biases that can affect your results. It's important to be aware of these
early on, so you can adjust for them and mention them in your report.
For example, Web of Science lacks many arts and social science journals.
To get better coverage, you might combine it with OpenAlex, which
includes more of these areas. If you do, make sure to note this in your
reporting.

The table below highlights the commonly used tools, their data coverage,
and commonly known limitations and biases in the dataset.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.1129}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2603}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.6255}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Tool Name} & \textbf{Coverage} & \textbf{Limitations \&
Biases} \\
\href{https://www.scopus.com/}{\textbf{Scopus}} &
\begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\item
  Includes more than 21,000 journal titles
\item
  Covers 50,000 books, 420 book series, 6.5 million conference
  proceedings, and 24 million patents
\item
  Strong coverage of science and technology journals and full Medline
  coverage; wide range of subject Clean/curated dataset
\item
  Good coverage of Elsevier titles
\item
  \href{https://supportcontent.elsevier.com/Support\%20Hub/DaaS/36182_Scopus_Custom_Data_Documentation_csv_txt_formats.pdf}{Scopus
  Metadata Documentation}
\end{itemize}
\end{minipage} & \begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\item
  Subscription required for access.
\item
  Relatively poor coverage of arts and humanities disciplines (recently
  improved as more journals have been added)
\item
  The citations and calculations based on them are only available from
  publications since 1996. This results in a very skewed h-index for
  researchers with longer careers than this
\item
  Citations to pre-1996 articles in articles published after 1996 are
  not included in the h-index calculation
\item
  Many journals are only covered for the last 5 years Scopus has
  been\href{https://link.springer.com/article/10.1007/s11192-015-1765-5}{recognized
  to have limited coverage of humanities, arts, and social sciences
  research as compared to the sciences}, as well as limited coverage of
  local and specialized journals, especially those written in languages
  other than English.
\item
  Scopus limits the number of records pulled to 2000 per download.~ This
  complicated the process of pulling the data set and required strategic
  narrowing and filtering.
\item
  Name variants and missing open access data appears to be an issue with
  journals with ``Letters'' in the title (e.g.~Physics Letter, Physics
  Letters Section B, The Journal Physical Chemistry Part C) and with
  authorship containing hundreds of names as a part of a collaboration.
\end{itemize}
\end{minipage} \\
Web of Science & \begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\item
  Clean/curated dataset
\item
  Over 95 million records and \textgreater{} 22,619 journals + books and
  conference proceedings
\item
  Strong coverage in STEM
\item
  \href{https://clarivate.libguides.com/librarianresources/coverage}{~Web
  of Science Coverage}
\item
  \href{https://support.clarivate.com/ScientificandAcademicResearch/s/article/Web-of-Science-Core-Collection-List-of-field-tags-in-output?language=en_US}{Web
  of Science Core Collection Field Tags}
\end{itemize}
\end{minipage} & \begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\item
  Subscription required for access.
\item
  Limitations only allow an export of 1,000 article records at a time,
  meaning that to build large datasets, one must export in batches and
  merge the outputs outside of WoS
\item
  WOS indexes only that which reaches a certain threshold of impact (as
  judged by Clarivate curators). Analyses run with WoS must therefore
  include this caveat, and sometimes require steps to be taken to try to
  account for this limitation
\item
  WoS does not capture corresponding authors. As a result, we had to
  work with RP (Reprint Address) to try to identify articles that have a
  corresponding author from UBC. Instead of relying on UBC email
  addresses, we had to rely on UBC mailing addresses. Either methodology
  presents challenges, as authors may give their personal address or
  email. In review of the test dataset, relying on the reprint address
  was deemed a reasonable method based on overall capture.
\item
  Web of Science has
  been\href{https://link.springer.com/article/10.1007/s11192-015-1765-5}{recognized
  to have limited coverage of humanities, arts, and social sciences
  research as compared to the sciences}, as well as limited coverage of
  local and specialized journals, especially those written in languages
  other than English
\end{itemize}
\end{minipage} \\
\href{https://www.lens.org/}{\textbf{Lens}} &
\begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\tightlist
\item
  Over 200 million scholarly records, compiled and harmonised from
  Microsoft Academic, PubMed and Crossref, enhanced with OpenAlex and
  UnPaywall open access information and links to ORCID
\end{itemize}
\end{minipage} & NOT FAMILIAR WITH THIS TOOL AND CAN'T FIND LITERATURE
ON THE BIASES AND LIMITATIONS. \\
\href{https://app.dimensions.ai/auth/base/landing?redirect=\%2Fdiscover}{\textbf{Dimensions}}
& \begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\tightlist
\item
  Contains data for 122 million publications, plus grants, policy, data,
  and metrics
\end{itemize}
\end{minipage} & \begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\item
  Subscription required for the full functionality and dataset.
\item
  Search options are limited in the free version.
\item
  The API and export functions are limited in the free version.
\item
  Corresponding Author information is provided (in the subscription
  version) by the publisher, but not all provide this information.
  Depending on which publisher you are interested in, this information
  may or may not be available.
\end{itemize}
\end{minipage} \\
\href{http://unpaywall.org/}{\textbf{Unpaywall}} &
\begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\item
  An open database of 53,067,737 free scholarly articles.
\item
  Harvesting Open Access content from over 50,000 publishers and
  repositories, and make it easy to find, track, and use.
\item
  Unpaywall is run by\href{https://ourresearch.org/}{OurResearch} a
  nonprofit
\item
  Unpaywall and the data contained are free
\item
  \href{https://unpaywall.org/data-format}{Unpayall data format}
\end{itemize}
\end{minipage} & \begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\item
  Unpaywall requires a DOI.
\item
  It can be difficult to generate a list of all DOIs you need,
  especially if you do not have access to a subscription tool.
\item
  Not all publications have a DOI. For example, transactions articles or
  conference papers are an important form of communication in many
  disciplines, but not all are assigned at DOI by the publisher.

  \begin{itemize}
  \tightlist
  \item
    In conducting an analysis of your institution's publishing, you
    would miss potentially a large portion of outputs if focusing only
    on items with DOI
  \end{itemize}
\end{itemize}
\end{minipage} \\
OpenAlex & \begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\tightlist
\item
  Attempts to offer a fulsome dataset that includes all research outputs
\end{itemize}
\end{minipage} & \begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\item
  Messy data: affiliation issues, article vs abstract
\item
  No reliable corresponding author data
\item
  ~Unable to select specific fields for export. Some dates, notably
  publication dates, come from external sources like publishers and are
  included in OpenAlex as-is. Dates in the future can be especially
  suspect.
\item
  inconsistencies in the implementation of open-access labeling,
  Particularly, when performing searches in the database, the authors
  found that the is\_oa filter, which indicates the availability of full
  texts, did not always match the actual open-access status of
  documents.
\item
  falls short in precise classification and accurate metadata management
  - ess abstracts and more inconsistencies in its handling of
  references.
\item
  ack the detailed categorization found in the other databases.
\item
  OpenAlex aggregates funding acknowledgments less precisely
\end{itemize}
\end{minipage} \\
\end{longtable}

\section{\texorpdfstring{\textbf{Reporting}}{Reporting}}\label{reporting}

Before starting your data collection and analysis, keep track of any
decisions or compromises you make. This helps ensure your findings are
clear and accurate for your audience. For example, if you use estimated
article processing charges (APCs) instead of exact prices, note this in
your report, ideally in a footnote or appendix. Tracking these details
also makes it easier to repeat your process for future or yearly
reports, especially if you plan to do a long-term study.

Commonly tracked decisions and compromises include:

\section{\texorpdfstring{\textbf{Additional
Considerations}}{Additional Considerations}}\label{additional-considerations}

\subsubsection{\texorpdfstring{\textbf{CRKN APC
Data}}{CRKN APC Data}}\label{crkn-apc-data}

If your institution is a part of the consortial agreements with the
Canadian Research Knowledge Network (CRKN). In that case, publishers
with agreements provide them with data on authors who have taken
advantage of the OA agreements. The citation data provided includes
institutional APC savings from the agreements. Using these reports from
publishers XXX; however, any OA agreements outside of the CRKN
consortial agreements will need to be extracted from elsewhere.~

\bookmarksetup{startatroot}

\chapter{Identifying affiliated
publications}\label{identifying-affiliated-publications}

\section{Selecting a data source}\label{selecting-a-data-source}

{[}include overview of main source options, but also explain why we
ultimately recommend OpenAlex and note that we will provide a sample
workflow for OpenAlex, but that other workflow documents exist for those
tools{]}~

\begin{tcolorbox}[enhanced jigsaw, opacitybacktitle=0.6, breakable, toprule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, coltitle=black, bottomtitle=1mm, left=2mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Quick tip}, arc=.35mm, rightrule=.15mm, colback=white, leftrule=.75mm, opacityback=0, colbacktitle=quarto-callout-tip-color!10!white, bottomrule=.15mm, titlerule=0mm]

We recommend OpenAlex as a free and open bibliographic database that
provides extra coverage of humanities, non-English languages, and the
Global South.

\end{tcolorbox}

https://\hyperref[0]{docs.google.com/document/d/1RToJwlr2ZdEF1F6FZRyh9izUj0j2llOdlA7tveutd30/edit?usp=sharing}~

\section{Extracting a publication dataset from
OpenAlex}\label{extracting-a-publication-dataset-from-openalex}

As a tool, OpenAlex is flexible and user-friendly. It offers several
different ways to interact and analyse data, ranging from an intuitive
user-interface, rest API access, and even a complete data snapshot
available for download. For the purpose of APC analysis, a search query
can be easily generated in the user-interface, accessible at
\href{http://openalex.org}{openalex.org}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  What are the ways to interact with OpenAlex

  a. OpenAlex website: \url{https://openalex.org/}

  b. OpenAlex API: \url{https://api.openalex.org/}~

  c. Complete data snapshot:
  \url{https://docs.openalex.org/download-all-data/openalex-snapshot}~

  d. As of Summer 2025, Alpha testing a custom query builder
\item
  Creating a dataset in the user interface

  a. Need to add data parameters~

  i. Year (optional, but likely useful for reporting purposes)

  ii. Institution

  iii. Type (set to article)

  iv. **if we use user interface, it is worth explaining why limiting to
  OA within the interface probably isn't the best way to limit our
  results (I think things like bronze or green are included and we only
  want gold/hybrid for APC calculation purposes)
\item
  Export ``works'' results and save to .csv
\item
  Do minimal clean up to data export before moving into other tools,
  like OpenRefine

  a. Which fields are necessary for the rest of the analysis?

  i. DOI

  ii. Open access status (hybrid or gold)

  iii. Publisher

  iv. Corresponding author information

  v. Journal information (ISSN or e-ISSN)

  vi. Funder information

  vii. APC information??
\end{enumerate}

\bookmarksetup{startatroot}

\chapter{Publication data cleanup and
refinement}\label{publication-data-cleanup-and-refinement}

\subsection{\texorpdfstring{\textbf{Selecting tools for data cleaning
and
refining}}{Selecting tools for data cleaning and refining}}\label{selecting-tools-for-data-cleaning-and-refining}

Before moving onto data cleaning, you will need to identify which tools
you will use. You should also keep in mind which program you will use to
clean the data at the stage of exporting data. For example, if using
Excel, it's easier to manage your data in .xlsx or.csv format rather
than .txt or .tsv.

You should select a program for handling data that you are comfortable
with. For beginners to this work, Microsoft Excel is a suitable choice.
For those with experience using OpenRefine, this program is useful for
batch cleaning large amounts of data. If you have experience using R or
JSON, this is an effective way to automate data cleaning and allows for
quick, iterative changes to your data cleaning preferences. In some
cases, you may use a mix of OpenRefine/programming language with Excel.

{[}maybe some general comments on possible tools to do this work -
people should use the tools they are comfortable with ultimately and
that will vary person to person. We can maybe note that with some
measure of proficiency in R or JSON you can automate some measure of the
work, but this may also be a deterrent for some who are not comfortable
with this.{]}

\subsection{\texorpdfstring{\textbf{Getting your data
ready}}{Getting your data ready}}\label{getting-your-data-ready}

First, you should understand how your data set describes publications
and become familiar with how data is reported. If you're new to working
with publication data, or using a new data source, it will be useful to
understand how that data source represents corresponding
authors/institutions, open access designations, and what data is
included/excluded in the data set. Some initial questions to consider:

\begin{itemize}
\item
  What column indicates the corresponding author? How can I determine
  the corresponding institution from this information?
\item
  If my institution has many affiliated research communities
  (i.e.~hospital networks), how are they represented in the data set?
\item
  What are the different open access designations? Are there any open
  access statuses which I want to exclude?~
\item
  Is there any missing data that I need for my assessment (i.e.~CC
  license, subject area, OA availability)
\item
  If I am matching this data set with another source, is there a
  matching identifier between the two sources that I can match on? (tip:
  take a DOI, from one data source and search for it in the second data
  source to confirm that the identifier is set up the same)
\end{itemize}

After becoming familiar with your data set, you can begin to prepare it
for data cleaning. Depending on the data source, you may have many
columns that are not needed for assessment (ex., Page numbers). To
improve the efficiency of your data set, identify columns that are
irrelevant to your assessment and delete these.

\subsection{\texorpdfstring{\textbf{Filter by open access
designation}}{Filter by open access designation}}\label{filter-by-open-access-designation}

\subsubsection{Limiting your results to open access publications only;
and OA publications where an APC was paid (hybrid and gold)
(APC-able)}\label{limiting-your-results-to-open-access-publications-only-and-oa-publications-where-an-apc-was-paid-hybrid-and-gold-apc-able}

\subsection{\texorpdfstring{\textbf{Filter by corresponding
author}}{Filter by corresponding author}}\label{filter-by-corresponding-author}

\subsubsection{Limiting your results to open access publications for
which an APC was paid by an institutional
affiliate}\label{limiting-your-results-to-open-access-publications-for-which-an-apc-was-paid-by-an-institutional-affiliate}

\begin{itemize}
\tightlist
\item
  Institution name may be spelled differently across publications, ex.
  University of Toronto, Univ Toronto, Univ of Toronto. A literal filter
  would exclude this but a regular expression pattern such as
  .*university of toronto.* would pick up most spelling variants.~
\end{itemize}

{[}we should have instructions for how to do this in excel and
openrefine. If people are using programming, i think they can handle
writing that query in whatever language they use{]}

Don't forget to mention:~

\begin{itemize}
\item
  If there are too many characters in a field, you may exceed the
  character length in Excel - but Google Sheets has more characters
  allowed per cell, so you can work around that way
\item
  Encoding as UTF-8 is vital when exporting can also be important to
  avoid errors in Excel
\end{itemize}

\bookmarksetup{startatroot}

\chapter{Estimating APC costs}\label{estimating-apc-costs}

There is no normalized, accurate, comprehensive data source that can be
relied upon to estimate APC costs. Therefore, you will need to draw on a
variety of sources depending on your research needs and factors like
institutional context.~~

Below, we include several well-used data sources, providing an overview
of the data source itself, its limitations, and options for gathering
and matching the data to your publications dataset.~

\begin{itemize}
\item
  Publisher reports (from CRKN)

  \begin{itemize}
  \item
    CRKN publication reports are the most reliable data source for
    determining actual publications from your institution with a
    specific publisher. They generally indicate the list price APC, any
    discount applied, and the total price paid (if any). They also
    provide accurate corresponding author information, which is used to
    determine eligibility for APC discounts or waivers. However, there
    are several limitations, including:
  \item
    The data is not normalized, and formatting is inconsistent.
  \item
    While articles covered under these agreements generally have no APC,
    the cost of publication is included within the larger agreement
    rather than at the article level. In other words, your institution
    is still paying some amount, just not via an APC.
  \item
    Generally, these agreements are based on the acceptance date, not
    the publication date.

    \begin{itemize}
    \item
      There may be other types of publications not covered under this
      agreement for which an APC was charged (such as a commentary).
    \item
      This data is also often available via an institutional dashboard
      supplied by the publisher.
    \end{itemize}
  \end{itemize}
\item
  OpenAPC

  \begin{itemize}
  \tightlist
  \item
    OpenAPC is an open dataset of APCs supplied by
    \href{https://github.com/OpenAPC/openapc-de}{consortia and
    institutions}. The dataset is entirely dependent on its
    contributors, and their methodologies and sources may, in turn,
    vary. Transformative Agreements generally do not include an APC and,
    therefore, are subject to the same limitations as CRKN data.
    OpenAlex uses OpenAPC data to determine
    \href{https://docs.openalex.org/api-entities/works/work-object\#apc_paid}{APC
    paid estimates}.
  \end{itemize}
\item
  Butler et. al (2024) dataset~
\end{itemize}

\begin{itemize}
\item
  This dataset contains and combines annual APC price lists from six
  publishers - Elsevier, Frontiers, PLOS, MDPI, Springer Nature, and
  Wiley from 2019 to 2023. It includes 8,712 unique journals and 36,618
  journal-year combinations.
\item
  The dataset includes the following metadata fields: publisher name,
  ISSN, journal, APC (converted to various currencies), APC date and
  year, source (Wayback Machine, publisher website, etc.). This
  information is explained in more detail in Table 2 of the accompanying
  \href{https://doi.org/10.48550/ARXIV.2406.08356}{data paper}.
\item
  The dataset also merges the variations of journal titles in publisher
  price lists from cleaning to a unique ID.~
\item
  Other potentially useful data points: journals that changed
  publishers, or flipped OA status (hybrid to gold and even gold to
  hybrid).~
\item
  Limitations:~

  \begin{itemize}
  \item
    The dataset is limited to 6 publishers.
  \item
    The dataset is compiled from publisher price lists and therefore
    replicates any inaccuracies from these price lists. For example,
    incorrect ISSNs,~ potentially incorrect OA statuses, or missing APC
    data due to society agreements or fees waived for newly established
    journals.~
  \end{itemize}
\end{itemize}

\begin{itemize}
\item
  The Directory of Open Access Journals (DOAJ):~

  \begin{itemize}
  \item
    DOAJ is a non-profit organization that provides an indexing database
    of fully open access journals from around the world, including
    journals that charge and do not charge APCs. To be included in the
    database, journals must apply and ensure they meet DOAJ criteria.
    Applications are managed and reviewed by its community of
    volunteers.~
  \item
    Many studies have used DOAJ data to analyze OA journals and trends.
    \href{https://doi.org/10.1002/leap.1558}{Borrego (2023)} discusses
    many of these studies.
    \href{https://doi.org/10.1007/s11192-023-04841-z}{Asai (2023)}
    details some of the DOAJ's strengths and limitations. For example,
    Asai explains that APCs in the DOAJ may not be up-to-date, and
    recommends using the price lists of the three leading publishers
    (Elsevier, Springer Nature, Wiley) from their websites (you can use
    the Butler et. al (2024) dataset for this purpose). In addition,
    DOAJ only includes fully OA journals, so any analysis will not
    estimate APC expenditure for hybrid OA articles.~
  \end{itemize}
\end{itemize}

How to gather the APC data:

\begin{itemize}
\item
  CRKN publication data is supplied via email on their collections list,
  generally quarterly. It can also be downloaded from the CRKN website
  in the relevant license profile (login required).
\item
  OpenAPC data is openly available on
  \href{https://github.com/OpenAPC/openapc-de}{GitHub}.
\item
  Butler et al.~(2024)
  \href{https://doi.org/10.7910/DVN/CR1MMV}{dataset}and accompanying
  \href{https://doi.org/10.48550/ARXIV.2406.08356}{data paper} outlining
  methodology and what the dataset contains.~~
\item
  DOAJ:~

  \begin{itemize}
  \tightlist
  \item
    To access their data, please refer to their ``documentation''
    section on the\href{https://doaj.org/}{DOAJ website}, as data can be
    accessed in various ways (API and OAI-PMH, CSV, public data dumps).~
  \end{itemize}
\end{itemize}

DOAJ data consists of journal-level and article-level metadata and can
be accessed in several ways. Refer to
the\href{https://doaj.org/terms/}{DOAJ Terms and Conditions} for a
complete description.

\bookmarksetup{startatroot}

\chapter{Combining APC costs with open access publication
data}\label{combining-apc-costs-with-open-access-publication-data}

\subsection{Accounting for transformative agreements and
discounts}\label{accounting-for-transformative-agreements-and-discounts}

In addition to the publisher-supplied publication data listed above,
it's important to include additional institutional or consortial-level
discounts. CRKN maintains a list of negotiated discounts
\href{https://www.crkn-rcdr.ca/en/apc-discounts}{here}. It is important
to note that many Read \& Publish agreements combine free OA publishing
in hybrid journals with only a discount for gold OA journals.
Institutional discounts may also be available, such as from
\href{https://www.mdpi.com/ioap}{MDPI}.

\subsection{Accounting for APCs for all
publications~}\label{accounting-for-apcs-for-all-publications}

Many APCs are paid by authors outside of existing OA agreements
(consortia or institutional). Estimates of APC expenditure can begin
with an overall analysis of all APCs paid by affiliated authors (any
affiliated authorâ†’corresponding author). This can be done by matching
publication data from a selected data source (see Step 1-2) with an APC
data source (e.g., CKRN, OpenAPC, Butler et. al (2024), DOAJ). Refer to
instructions in Step 5.~~

\section{\texorpdfstring{\textbf{Producing
estimates}}{Producing estimates}}\label{producing-estimates}

\subsubsection{Match APC prices to institutional
articles}\label{match-apc-prices-to-institutional-articles}

First, link APC prices (using the sources listed above: CRKN, OpenAPC,
Butler et al.~dataset, and DOAJ) to individual articles based on the
journal title. You can do this using common identifiers such as DOIs,
ISSNs, or journal titles (verified by publisher names). This may involve
extensive data work, such as cleaning and harmonizing data across
different datasets.

Example:

Name of article (DOI) -\textgreater{} match to Butler et al.~dataset.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Example executable code.}
\end{Highlighting}
\end{Shaded}

\subsubsection{Incorporate discounts and
waivers~}\label{incorporate-discounts-and-waivers}

We recommend you adjust for any known discounts or waivers your
institution provides or accesses through consortium negotiations (e.g.,
see CRKN-negotiated rates). Try to distinguish between prices listed by
the publisher and actual prices paid, wherever possible, by indicating
this in a new column. If prices are missing, we recommend applying a
median rather than an average.

Provide example.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Example executable code.}
\end{Highlighting}
\end{Shaded}

\subsubsection{Calculate the total
spend}\label{calculate-the-total-spend}

For an institutional-level analysis, aggregate this APC data by
publisher, journal, disciplines, faculty/department, author, etc.

Distinguish between OA status by producing separate estimates for:

\begin{itemize}
\item
  Gold open access
\item
  Hybrid open access
\item
  APCs covered under TAs, or discounts via consortia or institutionally
  negotiated agreements
\end{itemize}

We recommend including data on the number of articles used for each
category and providing some descriptive statistics, such as average,
median, range of APCs, skew, and standard deviation. This provides the
reader necessary information needed to critically understand the results
of your analysis.

\subsubsection{Clearly identify
gaps/limitations}\label{clearly-identify-gapslimitations}

Do your best to document gaps such as missing APC prices, articles that
could not be matched, or other challenges, such as discounts or waivers
that were unable to be accounted for. If comparing estimates to
subscription payments, consider where articles might fall under
subscriptions while also being counted as paid APC articles (hybrid).

\subsubsection{Data
visualizations/results}\label{data-visualizationsresults}

It may be useful to illustrate trends and patterns visible in the data.
Provide tables, charts, or narrative summaries of data to explain APC
estimates and how they were produced. We recommend keeping a detailed
log of your methods.

\bookmarksetup{startatroot}

\chapter{Additional considerations}\label{additional-considerations-1}

{[}If we want to include any further comments about how estimates can or
should be used within an institutional context?{]}

\bookmarksetup{startatroot}

\chapter{References and resources}\label{references-and-resources}




\end{document}
