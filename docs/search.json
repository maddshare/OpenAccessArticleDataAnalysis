[
  {
    "objectID": "Identifying_affiliated_publications.html",
    "href": "Identifying_affiliated_publications.html",
    "title": "2  Identifying affiliated publications",
    "section": "",
    "text": "2.1 Selecting a data source\n[include overview of main source options, but also explain why we ultimately recommend OpenAlex and note that we will provide a sample workflow for OpenAlex, but that other workflow documents exist for those tools]\nhttps://docs.google.com/document/d/1RToJwlr2ZdEF1F6FZRyh9izUj0j2llOdlA7tveutd30/edit?usp=sharing",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Identifying affiliated publications</span>"
    ]
  },
  {
    "objectID": "Identifying_affiliated_publications.html#selecting-a-data-source",
    "href": "Identifying_affiliated_publications.html#selecting-a-data-source",
    "title": "2  Identifying affiliated publications",
    "section": "",
    "text": "Quick tip\n\n\n\nWe recommend OpenAlex as a free and open bibliographic database that provides extra coverage of humanities, non-English languages, and the Global South.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Identifying affiliated publications</span>"
    ]
  },
  {
    "objectID": "Identifying_affiliated_publications.html#extracting-a-publication-dataset-from-openalex",
    "href": "Identifying_affiliated_publications.html#extracting-a-publication-dataset-from-openalex",
    "title": "2  Identifying affiliated publications",
    "section": "2.2 Extracting a publication dataset from OpenAlex",
    "text": "2.2 Extracting a publication dataset from OpenAlex\nAs a tool, OpenAlex is flexible and user-friendly. It offers several different ways to interact and analyse data, ranging from an intuitive user-interface, rest API access, and even a complete data snapshot available for download. For the purpose of APC analysis, a search query can be easily generated in the user-interface, accessible at openalex.org.\n\nWhat are the ways to interact with OpenAlex\na. OpenAlex website: https://openalex.org/\nb. OpenAlex API: https://api.openalex.org/ \nc. Complete data snapshot: https://docs.openalex.org/download-all-data/openalex-snapshot \nd. As of Summer 2025, Alpha testing a custom query builder\nCreating a dataset in the user interface\na. Need to add data parameters \ni. Year (optional, but likely useful for reporting purposes)\nii. Institution\niii. Type (set to article)\niv. **if we use user interface, it is worth explaining why limiting to OA within the interface probably isn’t the best way to limit our results (I think things like bronze or green are included and we only want gold/hybrid for APC calculation purposes)\nExport “works” results and save to .csv\nDo minimal clean up to data export before moving into other tools, like OpenRefine\na. Which fields are necessary for the rest of the analysis?\ni. DOI\nii. Open access status (hybrid or gold)\niii. Publisher\niv. Corresponding author information\nv. Journal information (ISSN or e-ISSN)\nvi. Funder information\nvii. APC information??",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Identifying affiliated publications</span>"
    ]
  },
  {
    "objectID": "Initial_considerations.html",
    "href": "Initial_considerations.html",
    "title": "1  Initial considerations",
    "section": "",
    "text": "1.1 Purpose\nIt’s hard to know exactly what a dataset can tell you until you’ve seen what’s in it. But starting with a few key questions can help you focus and choose the right data to analyze. With so many data points available, it can get overwhelming without a clear idea of what you’re looking for. The list below shows some areas you can explore using the tools mentioned in this document.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Initial considerations</span>"
    ]
  },
  {
    "objectID": "Initial_considerations.html#purpose",
    "href": "Initial_considerations.html#purpose",
    "title": "1  Initial considerations",
    "section": "",
    "text": "The yearly amount of money spent on APCs. \nThe yearly amount saved through discounts and memberships. \nType of OA model most prevalent, including the type of open licensed assigned to articles\nThe number of articles added/not added to your institutional repository. \nWhen the article was added to an OA repository using the oa-date and repository information from Unpaywall. This could yield interesting details on faculty processes for making content OA (e.g. pre-publication, post-publication, etc.)\nAnalyze the subject areas and faculties/departments where open access publishing is occurring/not occurring. This could assist with advocacy and outreach opportunities to promote OA.\nThe largest OA outputs by publisher. This could lead to negotiations around further discounts or moving toward transformative agreements.\nUsing the corresponding author data, gather emails for a research project on faculty OA practices.\nTrack and compare the impact of OA agreements over time. For example, if the Public Library of Science (PLOS) agreement started in 2023, tracking publications and comparing them with past years will show whether there is an increase in PLOS publications after the transformative agreement.\nEvaluate agreements for the OA Collection team to identify how much your institution publishes with the publisher. This will help guide what we consider for purchasing when we get requests.\nIdentify SSHRC/NSERC/CIHR-funded research meeting the OA requirements",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Initial considerations</span>"
    ]
  },
  {
    "objectID": "Initial_considerations.html#resources",
    "href": "Initial_considerations.html#resources",
    "title": "1  Initial considerations",
    "section": "1.2 Resources",
    "text": "1.2 Resources\nResourcing for data refining and analysis needs to be considered to ensure you are scoping your project appropriately.  The resources of time, people, training, and tools will impact what you can accomplish and will affect the “questions” you can answer with your dataset. \nThe workflows described here are meant to guide how to gather and analyze data based on the resources available to you at your institution. With this in mind, we offer both a scaled-down and scaled-up workflow in the second part of this document.  \nThe following sections outline key considerations on resourcing your data project.\n\n1.2.0.1 People & Time\nWith more time, the more detailed and comprehensive the dataset will be. \nTime for data pulling if using multiple datasets and merging. \nTime for data cleaning and refinement. \nExactness of the data takes time (gathering exact APC costs over estimates). \nMore staff/librarian support, the more work can be done on the data.\n\n\n1.2.0.2 Training\nKnowledge needed to complete the analysis - excel/open refine/R maybe\n\n\n1.2.0.3 Tools\nChoosing the right tool is the first step in collecting and analyzing data. No single tool covers everything, and each has its limits and biases that can affect your results. It’s important to be aware of these early on, so you can adjust for them and mention them in your report. For example, Web of Science lacks many arts and social science journals. To get better coverage, you might combine it with OpenAlex, which includes more of these areas. If you do, make sure to note this in your reporting.\nThe table below highlights the commonly used tools, their data coverage, and commonly known limitations and biases in the dataset.\n\n\n\nTool Name\nCoverage\nLimitations & Biases\n\n\nScopus\n\nIncludes more than 21,000 journal titles\nCovers 50,000 books, 420 book series, 6.5 million conference proceedings, and 24 million patents\nStrong coverage of science and technology journals and full Medline coverage; wide range of subject Clean/curated dataset\nGood coverage of Elsevier titles\nScopus Metadata Documentation\n\n\nSubscription required for access.\nRelatively poor coverage of arts and humanities disciplines (recently improved as more journals have been added)\nThe citations and calculations based on them are only available from publications since 1996. This results in a very skewed h-index for researchers with longer careers than this\nCitations to pre-1996 articles in articles published after 1996 are not included in the h-index calculation\nMany journals are only covered for the last 5 years Scopus has beenrecognized to have limited coverage of humanities, arts, and social sciences research as compared to the sciences, as well as limited coverage of local and specialized journals, especially those written in languages other than English.\nScopus limits the number of records pulled to 2000 per download.  This complicated the process of pulling the data set and required strategic narrowing and filtering.\nName variants and missing open access data appears to be an issue with journals with “Letters” in the title (e.g. Physics Letter, Physics Letters Section B, The Journal Physical Chemistry Part C) and with authorship containing hundreds of names as a part of a collaboration.\n\n\n\nWeb of Science\n\nClean/curated dataset\nOver 95 million records and &gt; 22,619 journals + books and conference proceedings\nStrong coverage in STEM\n Web of Science Coverage\nWeb of Science Core Collection Field Tags\n\n\nSubscription required for access.\nLimitations only allow an export of 1,000 article records at a time, meaning that to build large datasets, one must export in batches and merge the outputs outside of WoS\nWOS indexes only that which reaches a certain threshold of impact (as judged by Clarivate curators). Analyses run with WoS must therefore include this caveat, and sometimes require steps to be taken to try to account for this limitation\nWoS does not capture corresponding authors. As a result, we had to work with RP (Reprint Address) to try to identify articles that have a corresponding author from UBC. Instead of relying on UBC email addresses, we had to rely on UBC mailing addresses. Either methodology presents challenges, as authors may give their personal address or email. In review of the test dataset, relying on the reprint address was deemed a reasonable method based on overall capture.\nWeb of Science has beenrecognized to have limited coverage of humanities, arts, and social sciences research as compared to the sciences, as well as limited coverage of local and specialized journals, especially those written in languages other than English\n\n\n\nLens\n\nOver 200 million scholarly records, compiled and harmonised from Microsoft Academic, PubMed and Crossref, enhanced with OpenAlex and UnPaywall open access information and links to ORCID\n\nNOT FAMILIAR WITH THIS TOOL AND CAN’T FIND LITERATURE ON THE BIASES AND LIMITATIONS.\n\n\nDimensions\n\nContains data for 122 million publications, plus grants, policy, data, and metrics\n\n\nSubscription required for the full functionality and dataset.\nSearch options are limited in the free version.\nThe API and export functions are limited in the free version.\nCorresponding Author information is provided (in the subscription version) by the publisher, but not all provide this information. Depending on which publisher you are interested in, this information may or may not be available.\n\n\n\nUnpaywall\n\nAn open database of 53,067,737 free scholarly articles.\nHarvesting Open Access content from over 50,000 publishers and repositories, and make it easy to find, track, and use.\nUnpaywall is run byOurResearch a nonprofit\nUnpaywall and the data contained are free\nUnpayall data format\n\n\nUnpaywall requires a DOI.\nIt can be difficult to generate a list of all DOIs you need, especially if you do not have access to a subscription tool.\nNot all publications have a DOI. For example, transactions articles or conference papers are an important form of communication in many disciplines, but not all are assigned at DOI by the publisher.\n\nIn conducting an analysis of your institution’s publishing, you would miss potentially a large portion of outputs if focusing only on items with DOI\n\n\n\n\nOpenAlex\n\nAttempts to offer a fulsome dataset that includes all research outputs\n\n\nMessy data: affiliation issues, article vs abstract\nNo reliable corresponding author data\n Unable to select specific fields for export. Some dates, notably publication dates, come from external sources like publishers and are included in OpenAlex as-is. Dates in the future can be especially suspect.\ninconsistencies in the implementation of open-access labeling, Particularly, when performing searches in the database, the authors found that the is_oa filter, which indicates the availability of full texts, did not always match the actual open-access status of documents.\nfalls short in precise classification and accurate metadata management - ess abstracts and more inconsistencies in its handling of references.\nack the detailed categorization found in the other databases.\nOpenAlex aggregates funding acknowledgments less precisely",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Initial considerations</span>"
    ]
  },
  {
    "objectID": "Initial_considerations.html#reporting",
    "href": "Initial_considerations.html#reporting",
    "title": "1  Initial considerations",
    "section": "1.3 Reporting",
    "text": "1.3 Reporting\nBefore starting your data collection and analysis, keep track of any decisions or compromises you make. This helps ensure your findings are clear and accurate for your audience. For example, if you use estimated article processing charges (APCs) instead of exact prices, note this in your report, ideally in a footnote or appendix. Tracking these details also makes it easier to repeat your process for future or yearly reports, especially if you plan to do a long-term study.\nCommonly tracked decisions and compromises include:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Initial considerations</span>"
    ]
  },
  {
    "objectID": "Initial_considerations.html#additional-considerations",
    "href": "Initial_considerations.html#additional-considerations",
    "title": "1  Initial considerations",
    "section": "1.4 Additional Considerations",
    "text": "1.4 Additional Considerations\n\n1.4.0.1 CRKN APC Data\nIf your institution is a part of the consortial agreements with the Canadian Research Knowledge Network (CRKN). In that case, publishers with agreements provide them with data on authors who have taken advantage of the OA agreements. The citation data provided includes institutional APC savings from the agreements. Using these reports from publishers XXX; however, any OA agreements outside of the CRKN consortial agreements will need to be extracted from elsewhere.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Initial considerations</span>"
    ]
  },
  {
    "objectID": "Publication_data_cleaning_and_refinement.html",
    "href": "Publication_data_cleaning_and_refinement.html",
    "title": "3  Publication data cleanup and refinement",
    "section": "",
    "text": "3.0.1 Selecting tools for data cleaning and refining\nBefore moving onto data cleaning, you will need to identify which tools you will use. You should also keep in mind which program you will use to clean the data at the stage of exporting data. For example, if using Excel, it’s easier to manage your data in .xlsx or.csv format rather than .txt or .tsv.\nYou should select a program for handling data that you are comfortable with. For beginners to this work, Microsoft Excel is a suitable choice. For those with experience using OpenRefine, this program is useful for batch cleaning large amounts of data. If you have experience using R or JSON, this is an effective way to automate data cleaning and allows for quick, iterative changes to your data cleaning preferences. In some cases, you may use a mix of OpenRefine/programming language with Excel.\n[maybe some general comments on possible tools to do this work - people should use the tools they are comfortable with ultimately and that will vary person to person. We can maybe note that with some measure of proficiency in R or JSON you can automate some measure of the work, but this may also be a deterrent for some who are not comfortable with this.]\n\n\n3.0.2 Getting your data ready\nFirst, you should understand how your data set describes publications and become familiar with how data is reported. If you’re new to working with publication data, or using a new data source, it will be useful to understand how that data source represents corresponding authors/institutions, open access designations, and what data is included/excluded in the data set. Some initial questions to consider:\n\nWhat column indicates the corresponding author? How can I determine the corresponding institution from this information?\nIf my institution has many affiliated research communities (i.e. hospital networks), how are they represented in the data set?\nWhat are the different open access designations? Are there any open access statuses which I want to exclude? \nIs there any missing data that I need for my assessment (i.e. CC license, subject area, OA availability)\nIf I am matching this data set with another source, is there a matching identifier between the two sources that I can match on? (tip: take a DOI, from one data source and search for it in the second data source to confirm that the identifier is set up the same)\n\nAfter becoming familiar with your data set, you can begin to prepare it for data cleaning. Depending on the data source, you may have many columns that are not needed for assessment (ex., Page numbers). To improve the efficiency of your data set, identify columns that are irrelevant to your assessment and delete these.\n\n\n3.0.3 Filter by open access designation\n\n3.0.3.1 Limiting your results to open access publications only; and OA publications where an APC was paid (hybrid and gold) (APC-able)\n\n\n\n3.0.4 Filter by corresponding author\n\n3.0.4.1 Limiting your results to open access publications for which an APC was paid by an institutional affiliate\n\nInstitution name may be spelled differently across publications, ex. University of Toronto, Univ Toronto, Univ of Toronto. A literal filter would exclude this but a regular expression pattern such as .*university of toronto.* would pick up most spelling variants. \n\n[we should have instructions for how to do this in excel and openrefine. If people are using programming, i think they can handle writing that query in whatever language they use]\nDon’t forget to mention: \n\nIf there are too many characters in a field, you may exceed the character length in Excel - but Google Sheets has more characters allowed per cell, so you can work around that way\nEncoding as UTF-8 is vital when exporting can also be important to avoid errors in Excel",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Publication data cleanup and refinement</span>"
    ]
  },
  {
    "objectID": "Estimating_APC_costs.html",
    "href": "Estimating_APC_costs.html",
    "title": "4  Estimating APC costs",
    "section": "",
    "text": "There is no normalized, accurate, comprehensive data source that can be relied upon to estimate APC costs. Therefore, you will need to draw on a variety of sources depending on your research needs and factors like institutional context.  \nBelow, we include several well-used data sources, providing an overview of the data source itself, its limitations, and options for gathering and matching the data to your publications dataset. \n\nPublisher reports (from CRKN)\n\nCRKN publication reports are the most reliable data source for determining actual publications from your institution with a specific publisher. They generally indicate the list price APC, any discount applied, and the total price paid (if any). They also provide accurate corresponding author information, which is used to determine eligibility for APC discounts or waivers. However, there are several limitations, including:\nThe data is not normalized, and formatting is inconsistent.\nWhile articles covered under these agreements generally have no APC, the cost of publication is included within the larger agreement rather than at the article level. In other words, your institution is still paying some amount, just not via an APC.\nGenerally, these agreements are based on the acceptance date, not the publication date.\n\nThere may be other types of publications not covered under this agreement for which an APC was charged (such as a commentary).\nThis data is also often available via an institutional dashboard supplied by the publisher.\n\n\nOpenAPC\n\nOpenAPC is an open dataset of APCs supplied by consortia and institutions. The dataset is entirely dependent on its contributors, and their methodologies and sources may, in turn, vary. Transformative Agreements generally do not include an APC and, therefore, are subject to the same limitations as CRKN data. OpenAlex uses OpenAPC data to determine APC paid estimates.\n\nButler et. al (2024) dataset \n\n\n\nThis dataset contains and combines annual APC price lists from six publishers - Elsevier, Frontiers, PLOS, MDPI, Springer Nature, and Wiley from 2019 to 2023. It includes 8,712 unique journals and 36,618 journal-year combinations.\nThe dataset includes the following metadata fields: publisher name, ISSN, journal, APC (converted to various currencies), APC date and year, source (Wayback Machine, publisher website, etc.). This information is explained in more detail in Table 2 of the accompanying data paper.\nThe dataset also merges the variations of journal titles in publisher price lists from cleaning to a unique ID. \nOther potentially useful data points: journals that changed publishers, or flipped OA status (hybrid to gold and even gold to hybrid). \nLimitations: \n\nThe dataset is limited to 6 publishers.\nThe dataset is compiled from publisher price lists and therefore replicates any inaccuracies from these price lists. For example, incorrect ISSNs,  potentially incorrect OA statuses, or missing APC data due to society agreements or fees waived for newly established journals. \n\n\n\n\nThe Directory of Open Access Journals (DOAJ): \n\nDOAJ is a non-profit organization that provides an indexing database of fully open access journals from around the world, including journals that charge and do not charge APCs. To be included in the database, journals must apply and ensure they meet DOAJ criteria. Applications are managed and reviewed by its community of volunteers. \nMany studies have used DOAJ data to analyze OA journals and trends. Borrego (2023) discusses many of these studies. Asai (2023) details some of the DOAJ’s strengths and limitations. For example, Asai explains that APCs in the DOAJ may not be up-to-date, and recommends using the price lists of the three leading publishers (Elsevier, Springer Nature, Wiley) from their websites (you can use the Butler et. al (2024) dataset for this purpose). In addition, DOAJ only includes fully OA journals, so any analysis will not estimate APC expenditure for hybrid OA articles. \n\n\nHow to gather the APC data:\n\nCRKN publication data is supplied via email on their collections list, generally quarterly. It can also be downloaded from the CRKN website in the relevant license profile (login required).\nOpenAPC data is openly available on GitHub.\nButler et al. (2024) datasetand accompanying data paper outlining methodology and what the dataset contains.  \nDOAJ: \n\nTo access their data, please refer to their “documentation” section on theDOAJ website, as data can be accessed in various ways (API and OAI-PMH, CSV, public data dumps). \n\n\nDOAJ data consists of journal-level and article-level metadata and can be accessed in several ways. Refer to theDOAJ Terms and Conditions for a complete description.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimating APC costs</span>"
    ]
  },
  {
    "objectID": "Combining_APC_costs_with_open_access_publication_data.html",
    "href": "Combining_APC_costs_with_open_access_publication_data.html",
    "title": "5  Combining APC costs with open access publication data",
    "section": "",
    "text": "5.0.1 Accounting for transformative agreements and discounts\nIn addition to the publisher-supplied publication data listed above, it’s important to include additional institutional or consortial-level discounts. CRKN maintains a list of negotiated discounts here. It is important to note that many Read & Publish agreements combine free OA publishing in hybrid journals with only a discount for gold OA journals. Institutional discounts may also be available, such as from MDPI.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Combining APC costs with open access publication data</span>"
    ]
  },
  {
    "objectID": "Combining_APC_costs_with_open_access_publication_data.html#producing-estimates",
    "href": "Combining_APC_costs_with_open_access_publication_data.html#producing-estimates",
    "title": "5  Combining APC costs with open access publication data",
    "section": "5.1 Producing estimates",
    "text": "5.1 Producing estimates\n\n5.1.0.1 Match APC prices to institutional articles\nFirst, link APC prices (using the sources listed above: CRKN, OpenAPC, Butler et al. dataset, and DOAJ) to individual articles based on the journal title. You can do this using common identifiers such as DOIs, ISSNs, or journal titles (verified by publisher names). This may involve extensive data work, such as cleaning and harmonizing data across different datasets.\nExample:\nName of article (DOI) -&gt; match to Butler et al. dataset.\n\n## Example executable code.\n\n\n\n5.1.0.2 Incorporate discounts and waivers \nWe recommend you adjust for any known discounts or waivers your institution provides or accesses through consortium negotiations (e.g., see CRKN-negotiated rates). Try to distinguish between prices listed by the publisher and actual prices paid, wherever possible, by indicating this in a new column. If prices are missing, we recommend applying a median rather than an average.\nProvide example.\n\n## Example executable code.\n\n\n\n5.1.0.3 Calculate the total spend\nFor an institutional-level analysis, aggregate this APC data by publisher, journal, disciplines, faculty/department, author, etc.\nDistinguish between OA status by producing separate estimates for:\n\nGold open access\nHybrid open access\nAPCs covered under TAs, or discounts via consortia or institutionally negotiated agreements\n\nWe recommend including data on the number of articles used for each category and providing some descriptive statistics, such as average, median, range of APCs, skew, and standard deviation. This provides the reader necessary information needed to critically understand the results of your analysis.\n\n\n5.1.0.4 Clearly identify gaps/limitations\nDo your best to document gaps such as missing APC prices, articles that could not be matched, or other challenges, such as discounts or waivers that were unable to be accounted for. If comparing estimates to subscription payments, consider where articles might fall under subscriptions while also being counted as paid APC articles (hybrid).\n\n\n5.1.0.5 Data visualizations/results\nIt may be useful to illustrate trends and patterns visible in the data. Provide tables, charts, or narrative summaries of data to explain APC estimates and how they were produced. We recommend keeping a detailed log of your methods.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Combining APC costs with open access publication data</span>"
    ]
  },
  {
    "objectID": "Additional_considerations.html",
    "href": "Additional_considerations.html",
    "title": "6  Additional considerations",
    "section": "",
    "text": "[If we want to include any further comments about how estimates can or should be used within an institutional context?]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Additional considerations</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Open Access Article Data Analysis Workflow",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Preface"
    ]
  }
]